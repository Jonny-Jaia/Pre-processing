{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal: Automatic detection of image tilt angle\n",
    "- Input: \n",
    "    - 1 Normal image, \n",
    "    - 1 clockwise tilted image, \n",
    "    - 1 anticlock wise tilted image\n",
    "- Output: detect the angle and re-tilt an image for correction\n",
    "\n",
    "STEPS IMPLEMENTED:\n",
    "1. Explaination of Canny edges detections and Hough lines detections\n",
    "2. Calculation of angle of tilt in an image\n",
    "3. Correction in angle of an image\n",
    "\n",
    "THIS CAN BE USED:\n",
    "1. for the applications where we need normal image and not the tilted ones. For example in case of Tesseract OCR with increase in tilt angle of an image the output accuracy decreases. Therefore removing tilt is necessary in such cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "print(\"PIL version:\", PIL.__version__)\n",
    "import PIL.Image as Image\n",
    "import cv2         #for canny edge detection and hough line detection algorithm\n",
    "print(\"opencv version:\", cv2.__version__)\n",
    "import numpy as np\n",
    "print(\"Numpy version is:\", np.__version__)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "#inline to print in the notebook itself\n",
    "\n",
    "import scipy   # to add black bordered tilt to an image\n",
    "print('scipy version:', scipy.__version__)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function frequently used in the code\n",
    "def display_image(image):\n",
    "    plt.close()    #1st closing previously opened image to clean the memory \n",
    "    plt.figure(figsize=(10,10))#increase the size of the new image\n",
    "    \n",
    "    if len(image.shape) == 3: \n",
    "        if image.shape[2] == 3: #i.e. colour image or 3 channel\n",
    "            plt.imshow(image)\n",
    "        else: #gray image with 1 channel\n",
    "            plt.imshow(image, cmap=plt.cm.gray)\n",
    "    else:#gray image with len(image.shape) = 2\n",
    "        plt.imshow(image, cmap=plt.cm.gray)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = Image.open('DemoImage.png') #read image\n",
    "image  #print the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('DemoImage.png')\n",
    "display_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('DemoImage.png') \n",
    "\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  #convert BGR to RGB\n",
    "display_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) \n",
    "display_image(gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying canny edge detection:\n",
    "example: cv2.Canny(img_gray, 100, 100, apertureSize=3)\n",
    "(input_image, minVal, maxVal, aperture_size(the size of Sobel kernel used for find image gradients, By default it is 3), L2gradient: equation for finding gradient magnitude)\n",
    "\n",
    "\n",
    "#### aperture_size: \n",
    " - It is the size of Sobel kernel used for find image gradients. By default it is 3. \n",
    " - Aperture size should be odd between 3 and 7 in function 'Canny'\n",
    "\n",
    "#### Last argument is L2gradient \n",
    " - which specifies the equation for finding gradient magnitude. If it is True, it uses the equation mentioned above which is more accurate, otherwise it uses this function: Edge\\_Gradient \\; (G) = |G_x| + |G_y|. By default, it is False.\n",
    "\n",
    "\n",
    "### In cv2.Canny() following STEPS  are IMPLEMENTED:\n",
    "1. Noise Reduction:\n",
    "    - Since edge detection is susceptible to noise in the image, first step is to remove the noise in the image with a 5x5 Gaussian filter.\n",
    "2. Finding Intensity Gradient of the Image\n",
    "    - Smoothened image is then filtered with a Sobel kernel in both horizontal and vertical direction to get first derivative in horizontal direction (G_x) and vertical direction (G_y). \n",
    "3. Non-maximum Suppression: \n",
    "    - the result you get is a binary image with “thin edges”.\n",
    "4. Hysteresis Thresholding\n",
    "    - This stage decides which are all edges are really edges and which are not. For this, we need two threshold values, minVal and maxVal. Any edges with intensity gradient more than maxVal are sure to be edges and those below minVal are sure to be non-edges, so discarded. Those who lie between these two thresholds are classified edges or non-edges based on their connectivity. If they are connected to “sure-edge” pixels, they are considered to be part of edges. Otherwise, they are also discarded.\n",
    "    \n",
    "For more details please refer: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_canny/py_canny.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_canny_edge_detection_algorithm(img_gray, img_before):\n",
    "    \n",
    "    #4. Applying Canny Edge detection\n",
    "    #img_gray = cv2.cvtColor(img_before, cv2.COLOR_BGR2GRAY)\n",
    "    img_edges = cv2.Canny(img_gray, 100, 100, apertureSize=3)\n",
    "    #cv2.Canny Function: The function finds edges in the input image image and marks them \n",
    "    #in the output map edges using the Canny algorithm. \n",
    "    #The smallest value between threshold1 and threshold2 is used for edge linking. \n",
    "    #The largest value is used to find initial segments of strong edges. \n",
    "    return img_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_edges = apply_canny_edge_detection_algorithm(img_gray=gray, img_before=image)\n",
    "display_image(img_edges)   #(img_gray, 100, 100, apertureSize=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now on this we will apply Hough Lines\n",
    "    - returns ( rho (p) and theta (angle in radians))\n",
    "    - Parameters: (binary_image, rho, theta, threshold (minimum vote (number of points) or minimum len to consider as a line))\n",
    "1. First parameter, Input image should be a binary image, so apply threshold or use canny edge detection before finding applying hough transform. \n",
    "2. Second and third parameters are \\rho and \\theta accuracies respectively. \n",
    "3. Fourth argument is the threshold, which means minimum vote it should get for it to be considered as a line. Remember, number of votes depend upon number of points on the line. So it represents the minimum length of line that should be detected.\n",
    "\n",
    "https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_houghlines/py_houghlines.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# detecting the lines in an image\n",
    "def find_lines_using_hough_lines(img_edges):\n",
    "    \n",
    "    #5. Applying Hough LinesP: \n",
    "\n",
    "    \n",
    "    lines = cv2.HoughLines(img_edges, 1, math.pi / 180.0, 100)\n",
    "    #Hough Transform is a popular technique to detect any shape, if you can represent that shape\n",
    "    #in mathematical form. It can detect the shape even if it is broken or distorted a little bit. \n",
    "    \n",
    "    #returns ( rho (p) and theta (angle in radians))\n",
    "    #(binary_image, rho, theta, threshold (minimum vote (number of points) or minimum len to consider as a line))\n",
    "    \n",
    "    return lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lines = find_lines_using_hough_lines(img_edges)\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now on this we will apply Hough LinesP\n",
    "     - returns ( rho (p) and theta (angle in radians))\n",
    "     - Parameters: (binary_image, rho, theta, threshold (minimum vote (number of points) or minimum len to consider as a line), \n",
    "    minLineLength: Line segments shorter than this are rejected, \n",
    "    maxLineGap: Maximum allowed gap between line segments to treat them as single line)\n",
    "    \n",
    "##### Probabilistic Hough Transform\n",
    "In the hough transform, you can see that even for a line with two arguments, it takes a lot of computation. Probabilistic Hough Transform is an optimization of Hough Transform we saw. It doesn’t take all the points into consideration, instead take only a random subset of points and that is sufficient for line detection. Just we have to decrease the threshold. See below image which compare Hough Transform and Probabilistic Hough Transform in hough space.\n",
    "\n",
    "- minLineLength - Minimum length of line. Line segments shorter than this are rejected.\n",
    "- maxLineGap - Maximum allowed gap between line segments to treat them as single line.\n",
    "returns ( rho (p) and theta (angle in radians))\n",
    "(binary_image, rho, theta, threshold (minimum vote (number of points) or minimum len to consider as a line), \n",
    "    minLineLength: Line segments shorter than this are rejected, \n",
    "    maxLineGap: Maximum allowed gap between line segments to treat them as single line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# detecting the lines in an image\n",
    "def find_lines_using_hough_lines(img_edges):\n",
    "    \n",
    "    #5. Applying Hough LinesP: \n",
    "\n",
    "    \n",
    "    lines = cv2.HoughLinesP(img_edges, 1, math.pi / 180.0, 100, minLineLength=100, maxLineGap=5)\n",
    "    #Hough Transform is a popular technique to detect any shape, if you can represent that shape\n",
    "    #in mathematical form. It can detect the shape even if it is broken or distorted a little bit. \n",
    "    \n",
    "    #returns ( rho (p) and theta (angle in radians))\n",
    "    #(binary_image, rho, theta, threshold (minimum vote (number of points) or minimum len to consider as a line), \n",
    "    # minLineLength: Line segments shorter than this are rejected, \n",
    "    # maxLineGap: Maximum allowed gap between line segments to treat them as single line)\n",
    "    \n",
    "    return lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linesP = find_lines_using_hough_lines(img_edges)\n",
    "print(linesP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the angle of an image:\n",
    "- since this image is not tilted then output should be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_angle(lines, img_before):\n",
    "    angles = []\n",
    "#    print('Lines:', lines)\n",
    "    for x1, y1, x2, y2 in lines[0]:\n",
    "#        print('In lines we have x1, y1, x2, y2:',x1, y1, x2, y2)\n",
    "        \n",
    "        #Drawing lines\n",
    "        cv2.line(img_before, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
    "        # The function line draws the line segment between pt1 (x1) and pt2(y1) points in the image. \n",
    "        #The line is clipped by the image boundaries. \n",
    "        \n",
    "        #calculating tilt angle\n",
    "        angle = math.degrees(math.atan2(y2 - y1, x2 - x1))  # find angle of line connecting (0,0) to (x,y) from +ve x axis\n",
    "        #The Math.atan2() function returns the angle in the plane (in radians) \n",
    "        #between the positive x-axis and the ray from (0,0) to the point (x,y), for Math.atan2(y,x)\n",
    "        #atan2(y, x) returns value of atan(y/x) in radians. The atan2() method returns a numeric \n",
    "        #value between – and representing the angle of a (x, y) point and positive x-axis.\n",
    "        print('Tilt angle for x1, y1, x2, y2 {} is {}'.format([x1, y1, x2, y2], angle) )\n",
    "        angles.append(angle)\n",
    "        \n",
    "    median_angle = np.median(angles)\n",
    "    print('median_angle:', median_angle)\n",
    "    return median_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calculate_angle(lines =linesP, img_before = image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building End-to-End Auto tilt detector in input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('DemoImage.png') \n",
    "\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  #convert BGR to RGB\n",
    "display_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NoTiltImage = image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imutils # to rotate image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tiltClockWise = imutils.rotate_bound(image, 3)\n",
    "display_image(tiltClockWise)\n",
    "tiltAntiClockWise = imutils.rotate_bound(image, -3)\n",
    "display_image(tiltAntiClockWise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE: After introduction of tilt we can see in the black colour is padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def auto_tilt_detection(image):\n",
    "    #1. convert image to gray colour\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) \n",
    "    #2. apply cany edge detection\n",
    "    img_edges = apply_canny_edge_detection_algorithm(img_gray=gray, img_before=image)\n",
    "    display_image(img_edges)   #(img_gray, 100, 100, apertureSize=3)\n",
    "    #3. apply Hough lines detection\n",
    "    linesP = find_lines_using_hough_lines(img_edges)\n",
    "    print(linesP)\n",
    "    #4. Calculate angle\n",
    "    img_before = image\n",
    "    median_angle = calculate_angle(linesP, img_before)\n",
    "    \n",
    "    return median_angle\n",
    "    \n",
    "def correction_in_an_image(image):\n",
    "    # detect tilt angle in an image\n",
    "    median_angle = auto_tilt_detection(image)\n",
    "    # correction\n",
    "    image = imutils.rotate_bound(image, -median_angle)\n",
    "    print(\"image after correction:\")\n",
    "    display_image(image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correction_in_an_image(NoTiltImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correction_in_an_image(tiltClockWise)  # detected tilt 2.96 ~ 3 degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correction_in_an_image(tiltAntiClockWise)  # detected tilt -2.7 ~ -3 degrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that at the time of introduction of tilt black paddin get introduced therefore we can see it in the output as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Adhar",
   "language": "python",
   "name": "adhar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
